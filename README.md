# ETL Data Pipelines With Airflow 
# Building Data Pipeline With Airflow For Covid_19 Data 

## Title: ETL With Airflow
## Description

An ETL pipeline built using Apache Airflow to extract data from PostgreSQL and a CSV file, perform data transformations, and load it into PostgreSQL tables.

## Overview
Objective: The primary aim is to automate the extraction, transformation, and loading of COVID-19 data into structured tables in a PostgreSQL database.

## Technologies Used:
* Apache Airflow
* Python
* Pandas
* SQLAlchemy
* PostgreSQL

## Project Stages:

**1- Data Extraction: 

* Extract data from  2 sources ( postgres - csv files )

**2- Data Transformation:**

* To ensure data quality and accuracy, we performed data cleansing and preprocessing tasks. This step involved handling removing column , ,add dailychange column and transforming data to make it easy to analysis .

**3- Create Tables In Postgresql :**

* Create 3 tables in postgresql  

**4- Loading data into postgresql 


